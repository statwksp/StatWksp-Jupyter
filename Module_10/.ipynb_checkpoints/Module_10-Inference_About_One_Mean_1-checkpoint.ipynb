{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10: Inference About a Population Mean I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we discuss confidence intervals and hypothesis tests about a single parameter, the population mean. We start by assuming that the population standard deviation is known, and present the Z-confidence interval and Z-test. In the next module, we remove this assumption and present the T-confidence interval and T-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Z-confidence interval assumes that our data are normally distributed and that we know the population standard deviation (sd). In practice, we rarely know the population sd, but this is a useful setting for studying the basics of confidence intervals. \n",
    "\n",
    "All confidence intervals are of the form: (estimate) $\\pm$ (margin of error). In the Z-confidence interval, the estimate is $\\bar{x}$, the sample mean, and the margin of error is a critical value from the standard normal distribution times the standard error of $\\bar{x}$, $\\sigma/\\sqrt{n}$. \n",
    "\n",
    "Suppose that we have 10 observations from a normal distribution, and that we know the standard deviation of this normal distribution is three. Let's make a 95% confidence interval for the mean of our normal distribution. Remember that we calculate the mean of a sample using the \"mean()\" function. We can also get a percentile from the normal distribution by using the \"qnorm()\" function. We calculate square roots in R with the \"sqrt()\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = c(4,3,6,6,3,5,6,7,7,3)\n",
    "x.bar = mean(data) #Sample mean\n",
    "SE = 3/sqrt(10) #Sample standard error\n",
    "z.star = qnorm(0.975) #Standard normal critical value\n",
    "MOE = z.star * SE #Margin Of error\n",
    "lcl = x.bar - MOE #Lower endpoint of our confidence interval\n",
    "ucl = x.bar + MOE #Upper endpoint of our confidence interval\n",
    "print(lcl)\n",
    "print(ucl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower and upper endpoints of a confidence interval are sometimes called the lower confidence limit and upper confidence limit respectively.\n",
    "\n",
    "The sample we used in this example was generated from a normal distribution with standard deviation three and mean five, so our confidence interval does contain the true mean of the distribution. If we generate new data and calculate a new confidence interval many times, eventually we will get intervals that do not contain the true mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A question that often arises when planning a study is how large of a sample is required. In general, this question is quite difficult to answer. If we are trying to find a confidence interval for the mean of a normal population with known variance however, there is a formula for the necessary sample size. This formula depends on the confidence level, the population standard deviation and the desired margin of error. Therefore, we must choose an acceptable margin of error before we can determine an appropriate sample size.\n",
    "\n",
    "Consider the distribution in our last example, normal with a standard deviation of three. Let's find how many observations we would need to get a $95\\%$ confidence interval of width no more than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = 3 #Population standard deviation\n",
    "MOE = 2 #Margin of error = half of width\n",
    "Z.star = qnorm(p=0.975) #Critical value from a standard normal\n",
    "n = (Z.star*sd/MOE)^2 #Sample size formula\n",
    "print(\"Sample size must be at least:\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we need at least 9 observations, since it is impossible to sample 0.643282 of a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Tests for the Population Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move on to hypothesis testing. All hypothesis tests are based on a test statistic. Many of these statistics are of the form: (estimate minus hypothesised value) divided by the standard error of the estimate.\n",
    "\n",
    "The Z-test for the population mean assumes that our data are normally distributed, and that we know the population (i.e., true) standard deviation. We start with a null hypothesis about the population mean, such as \"the population mean is equal to one\". We also need an alternative hypothesis, such as \"the population mean is greater than one\". \n",
    "\n",
    "The test statistic for the Z-test is called the Z-statistic. It uses the sample mean, $\\bar{x}$, as an estimate, and the true standard error of $\\bar{x}$, $\\sigma/\\sqrt{n}$, in the denominator.\n",
    "\n",
    "The p-value of our test is the probability of observing a test statistic at least as extreme as the one we got, in the direction of the alternative. We calculate a p-value based on the Z-statistic. If the p-value is less than the significance level of our test, $\\alpha$, we reject our null hypothesis in favor of the alternative hypothesis. If the p-value is greater than $\\alpha$ then we do not reject the null hypothesis (note that 'not rejecting' the null is not the same as accepting it).\n",
    "\n",
    "Suppose that we have another 10 observations from a normal distribution, but this time we know that the population standard deviation is 20. Run the following code, which reads-in a dataset from the file \"Sample_Data.csv\" (this dataset has no variable name). Next, we test the null hypothesis that the population mean is two against the alternative hypothesis that the population mean is greater than two. Let's use $\\alpha=0.05$ as our significance level. Remember that the \"pnorm()\" function gets probabilities from the normal distribution and that the \"lower.tail\" option can be set to \"T\" or \"F\" to get lower tail or upper tail probabilities respectively. See Module 5 for more details on the \"pnorm()\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(\"Sample_Data.csv\", header=FALSE)\n",
    "names(data) = c(\"X\")\n",
    "x.bar = mean(data$X) #Sample mean\n",
    "mu = 2 #Hypothesised population mean\n",
    "SE = 20/sqrt(10) #Standard error of x.bar\n",
    "Z = (x.bar - mu)/SE #Z-statistic\n",
    "p.value = pnorm(Z, lower.tail=F) #Probability of being greater than Z\n",
    "print(p.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated our p-value as the probability that a standard normal is **greater than** our observed Z-statistic. This is because our alternative says that the mean is **greater than** two.\n",
    "\n",
    "Our p-value (0.02317264) is less than $\\alpha$, so we reject the null hypothesis and conclude that the population mean is greater than two.\n",
    "\n",
    "For comparison, let's do a test with the same data and null hypothesis, but this time our alternative will be that the population mean is less than two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(\"Sample_Data.csv\", header=FALSE)\n",
    "names(data) = c(\"X\")\n",
    "x.bar = mean(data$X) #Sample mean\n",
    "mu = 2 #Hypothesised population mean\n",
    "SE = 20/sqrt(10) #Standard error of x.bar\n",
    "Z = (x.bar - mu)/SE #Z-statistic\n",
    "p.value = pnorm(Z, lower.tail=T) #Probability of being less than Z\n",
    "print(p.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, our p-value is much greater than $\\alpha$, so we do not reject our null hypothesis. This p-value is the probability of being **less than** our Z-statistic because our alternative hypothesis says that the population mean is **less than** two.\n",
    "\n",
    "Both of the alternative hypothesis that we have looked at so far are called one-sided because they say that the population mean falls on one side of the null hypothesis value. The last type of alternative hypothesis that we can have is called two-sided. Two-sided hypotheses say that the population mean is not equal to the null hypothesis value (that is, that the population mean can fall on either side of the null hypothesis value).\n",
    "\n",
    "Let's use the same data and null hypothesis from the last two examples, but this time we will use the alternative hypothesis that the population mean is not equal to two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(\"Sample_Data.csv\", header=FALSE)\n",
    "names(data) = c(\"X\")\n",
    "x.bar = mean(data$X) #Sample mean\n",
    "mu = 2 #Hypothesised population mean\n",
    "SE = 20/sqrt(10) #Standard error of x.bar\n",
    "Z = (x.bar - mu)/SE #Z-statistic\n",
    "p.value = 2*pnorm(abs(Z), lower.tail=F) #Double the probability of being \n",
    "                                        #greater than the absolute value of Z\n",
    "print(p.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value is barely less than $\\alpha$, so we reject our null hypothesis, but these results are not extremely compelling.\n",
    "\n",
    "Notice that the way we calculated our p-value in this example was a bit different from the other two. First, we made our Z-statistic positive by taking its absolute value. This makes sure that we are calculating the probability of being farther than Z from the value in the null hypothesis. Second, we double the probability that we calculate. This is because, in a two-sided test, we are interested in values that are either far greater or far smaller than the hypothesized population mean. Doubling our probability ensures that we have accounted for both of these possibilities. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
