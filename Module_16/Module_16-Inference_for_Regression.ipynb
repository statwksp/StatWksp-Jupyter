{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 16: Inference for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we discuss how to do several forms of inference about regression models. In particular, we examine how to test the hypothesis of no relationship between our two variables using both the slope parameter and the correlation. We also examine how to make confidence intervals for the slope parameter, the mean response at any point and a future value of the response at any point.\n",
    "\n",
    "Before performing inference, it is important to first check the conditions for linear regression. In Module 6, we discussed how to construct residual plots for this purpose. For Module 16, we will assume that we have found no troublesome departures from the conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for a Linear Relationship I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first steps of linear regression modelling is to check whether there is a linear relationship for us to study. Our null hypothesis is that there is no linear relationship, while our alternative hypothesis is that the relationship is linear. Alternatively, we can specify the direction of the relationship in our alternative hypothesis, thus making our test one-sided.\n",
    "\n",
    "We can test this null hypothesis in two different ways. The first method is to use the slope parameter. We can re-write our null and alternative hypotheses as 'the slope parameter is zero' and 'the slope parameter is not zero', respectively. \n",
    "\n",
    "We carry out the test for a slope parameter being zero in R by first fitting our regression model using the \"lm()\" function, then using the \"summary()\" function. The \"summary()\" function has one input: \"x\". This \"x\" input is the \"lm\" object that we are interested in.\n",
    "\n",
    "Let's test for a linear relationship between temperature and number of bikes rented in the bike-sharing data from Module 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read-in the bike-sharing data\n",
    "data.bikes = read.csv(file = \"Bikes.csv\")\n",
    "\n",
    "# Fit a linear model\n",
    "reg.bikes = lm(formula = Bikes ~ Temp, data = data.bikes)\n",
    "\n",
    "# Test our hypothesis that the slope parameter is zero\n",
    "summary(reg.bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information in this output. The part that we are interested in is the \"Coefficients:\" table, which includes the parameters for the intercept and slope. The slope is the coefficient for the explanatory variable, which is \"Temp\" in this example. The column called \"$Pr(>|t|)$\" gives the p-values for testing whether the corresponding parameter is equal to zero.\n",
    "\n",
    "For this dataset, our p-value is $1.24 * 10^{-13}$, which is much smaller than our cutoff of 0.05. We can therefore conclude that there is a linear relationship between temperature and number of bikes rented.\n",
    "\n",
    "Advanced Topic: It is common to omit the name of the \"formula\" input in the \"lm\" function. This is fine, as long as we enter the \"formula\" input first. We can fit our linear regression model using the following, shorter, code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg.bikes = lm(Bikes ~ Temp, data = data.bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most functions in R have a correct order for entering their inputs. As long as we stick to this order, we do not have to enter the inputs' names. You can find this correct order by looking at the documentation for these functions on https://www.rdocumentation.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for a Linear Relationship II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the null hypothesis that we wanted to test in the previous section: 'there is no linear relationship between our two variables'. The corresponding two-sided alternative is: 'there is a linear relationship between our two variables', and the corresponding one-sided alternatives are similar. \n",
    "\n",
    "Remember that correlation measures the linear relationship between two variables, so we can re-write these hypotheses the correlation. Our null hypothesis becomes: 'the correlation between our two variables is zero', and our alternative hypothesis becomes: 'the correlation between our two variables is not zero'. \n",
    "\n",
    "We test for whether the correlation is zero in R using the \"cor.test()\" function. This function has two main inputs: \"x\" and \"y\". The inputs \"x\" and \"y\" are the two variables that we are studying.\n",
    "\n",
    "The \"cor.test()\" function has a third, optional, input called \"alternative\". The \"alternative\" input lets us specify if the alternative hypothesis is \"two.sided\", \"less\" or \"greater\" by setting \"alternative\" equal to the corresponding value. The default value of \"alternative\" is \"two.sided\", so we only need to include this input if we have a one-sided alternative.\n",
    "\n",
    "Let's test whether the correlation between temperature and number of bikes rented is zero. Remember that we can use \"$\" to get these variables from our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.test(x = data.bikes$Bikes, y = data.bikes$Temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is given at the end of the row below \"data:\". Our p-value is $1.245 * 10^{-13}$ which is the same as the one we got in the previous section if we ignore roundoff error. These two p-values are the same because the two tests we discussed are testing the same hypotheses: whether there is a linear relationship between our two variables or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Slope Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often helpful to make a confidence interval for the slope parameter, in addition to our hypothesis test. Remember that confidence intervals give a range of reasonable values for a parameter.\n",
    "\n",
    "We can get a confidence interval for the slope parameter in R by using the \"confint()\" function. The \"confint()\" function has one main input: \"object\". We set \"object\" equal to the \"lm\" object that contains our regression model.\n",
    "\n",
    "Let's get a confidence interval for the slope parameter in the regression of number of bikes rented on temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint(reg.bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Temp\" row corresponds to the slope parameter, so our confidence interval is $(76.7, 122.6)$, after rounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals for Mean Response and Future Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have studied how to do inference about the slope parameter in a regression model. We might also want to learn about the mean of the response variable for a particular value of the predictor variable. A similar problem is to learn about future values of the response variable for a particular value of the predictor variable. We can get confidence intervals for both of these quantities using the \"predict()\" function on our \"lm\" object. Confidence intervals for future observations are usually called prediction intervals.\n",
    "\n",
    "The \"predict()\" function has three main inputs: \"object\", \"newdata\" and \"interval\". The \"object\" input is the \"lm\" object containing our regression model. The \"newdata\" input is a data frame containing the values of the predictor variable that we are interested in. We will elaborate on this shortly. The \"interval\" input is set to \"confidence\" if we want a confidence interval or \"prediction\" if we want a prediction interval for future observations.\n",
    "\n",
    "The \"newdata\" input tells R which values of the predictor vaiable we are interested in. However, the value we use for this input must be formatted as a data frame. Further, the data frame we use must have a variable with the same name as the predictor variable in our \"lm\" object.\n",
    "\n",
    "Let's get a confidence interval for the mean number of bikes rented when the temperature is 15 degrees Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame for the \"newdata\" input\n",
    "mean.data = data.frame(Temp = 15)\n",
    "\n",
    "# Get our confidence interval\n",
    "predict(object = reg.bikes, newdata = mean.data, interval = \"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"fit\" column gives the estimated number of bikes, while \"lwr\" and \"upr\" give the lower and upper enpoints of our confidence interval respectively. Therefore, after rounding, our estimate for the number of bikes rented is 2100, and our confidence interval is (1977, 2222).\n",
    "\n",
    "It is helpful to have an estimate for the average number of bikes rented, but if we want to know how many bikes we need to have available when we expect the temperature to hit a certain value in the future, we should get a prediction interval for that future value. Let's get prediction intervals for the number of bikes we will need when the temperature is 10, 15 and 20 degrees Celsius. We are interested in three different values of Temp, so we will need to use the \"c()\" function to set Temp equal to a list of values in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame for the \"newdata\" input\n",
    "pred.data = data.frame(Temp = c(10, 15, 20))\n",
    "\n",
    "# Get our prediction intervals\n",
    "predict(object = reg.bikes, newdata = pred.data, interval = \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the \"fit\" column gives the predicted number of bikes, while \"lwr\" and \"upr\" give the lower and upper enpoints of our prediction intervals respectively. Therefore, after rounding, our prediction intervals for 10, 15 and 20 degrees are (657, 2545), (1153, 3046) and (1635, 3561) respectively. Notice that the prediction interval for Temp=15 is much wider than the confidence interval we obtained for the mean number of bikes rented at 15 degrees. This difference is because there is more variability associated with estimating an observed value rather than a mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
